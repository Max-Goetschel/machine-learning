{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Machine Learning\n",
    "\n",
    "### *Session \\#3*\n",
    "\n",
    "\n",
    "### Helpful shortcuts\n",
    "---\n",
    "\n",
    "**SHIFT** + **ENTER** ----> Execute Cell\n",
    "\n",
    "**UP/DOWN ARROWS** --> Move cursor between cells (then ENTER to start typing)\n",
    "\n",
    "**TAB** ----> See autocomplete options\n",
    "\n",
    "**ESC** then **b** ----> Create Cell \n",
    "\n",
    "**ESC** then **dd** ----> Delete Cell\n",
    "\n",
    "**\\[python expression\\]?** ---> Explanation of that Python expression\n",
    "\n",
    "**ESC** then **m** then __ENTER__ ----> Switch to Markdown mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. KNN Regression and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Linear Regression \n",
    "\n",
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose model and hyperparameters:**\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit model to data:**`model.fit(X_train, y_train)`                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use model to predict:** `y_predicted = model.predict(X_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find average error:** \n",
    "```python\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_predicted, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find R2 score:** `model.score(X_test, y_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Create a LinearRegression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Fit the model using** `X_train` **and** `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Make a** `y_predicted` **variable using** `model.predict()` **on** `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Use** `y_predicted` **and** `y_test` **to find the mean absolute error of your model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Use** `X_test` **and** `y_test` **to find the R2 score of your model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from yellowbrick.features import rank1d, rank2d\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from yellowbrick.model_selection import LearningCurve, ValidationCurve\n",
    "\n",
    "df = pd.read_csv(\"diamonds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare datasets**\n",
    "```python\n",
    "X = df.drop(['price'], 1)\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split pipeline between numeric/categorical**: \n",
    "```python\n",
    "numeric = ['x', 'y', 'z', 'carat', 'table', 'depth']\n",
    "categorical = ['cut', 'color', 'clarity']\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "        (StandardScaler(), numeric),\n",
    "        (OneHotEncoder(), categorical)\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add yellowbrick visualizer and train model:** \n",
    "```\n",
    "model = ResidualsPlot(LinearRegression())\n",
    "pipeline = make_pipeline(transformer, model)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit and score model:** \n",
    "```\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Separate the dataframe into** `X_train`, `y_train`, `X_test`, `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Use a ColumnTransformer to create a model with both** `OneHotEncoder()` **and** `StandardScaler()` **preprocessing for the appropriate columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Add a ResidualsPlot visualizer to the model, and fit to** `X_train`. **What target values does the model have the most difficulty with?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Rerun the above code, but add a LearningCurve visualizer to the model instead. Does the model need more data or not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Bias, Variance and Polynomial Regression\n",
    "\n",
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---\n",
    "\n",
    "**Add polynomial features to model:**\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
    "model.fit(X[['carat']], y)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('polynomialfeatures',\n",
       "                 PolynomialFeatures(degree=2, include_bias=True,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('linearregression',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "model.fit(X[['carat']], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict and plot using model** \n",
    "```python\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(X[['carat']], y)\n",
    "plt.scatter(X[['carat']], model.predict(X[['carat']]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a validation curve to test different polynomial degrees**\n",
    "```python\n",
    "model = make_pipeline(PolynomialFeatures(), LinearRegression())\n",
    "model = ValidationCurve(model, \n",
    "                        param_name='polynomialfeatures__degree', \n",
    "                        param_range=range(1, 5))\n",
    "\n",
    "model.fit(X[['carat']], y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Train a polynomial regression model using all the numeric columns** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Use a validation curve to test polynomial degrees up to 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. At what degree does the model start to overfit?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Regularization\n",
    "\n",
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---\n",
    "**Train a ridge regression model:**\n",
    "```python\n",
    "model = Ridge(alpha=1)\n",
    "pipeline = make_pipeline(transformer, model)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a lasso regression model:**\n",
    "```python\n",
    "model = Lasso(alpha=1)\n",
    "pipeline = make_pipeline(transformer, model)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get coefficients from classifier in Pipeline:** `model.coef_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Train a Ridge Regression model on the entire diamond dataset, as in exercise set 1. What range works best for the alpha parameter?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Access the coefficients from the trained Ridge model. Which features were most important and least important?** \n",
    "\n",
    "*Hint: You can get the column names from* `df[numeric].columns` *and* `transformer.get_feature_names()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Train a Lasso Regression model on the entire diamond dataset, as in exercise set 1. What range works best for the alpha parameter?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Access the coefficients from the trained Lasso model. How many features were eliminated?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from yellowbrick.target import ClassBalance\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_excel('titanic.xlsx').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into data sets**: \n",
    "```python\n",
    "X = df[['age']]\n",
    "y = df['survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and fit classifier**: \n",
    "```python\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use model to classify**: `model.predict(X_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use model to get probabilities**: `model.predict_proba(X_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Copy/paste the slope from** `model.coef_` **and the intercept from** `model.intercept_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plot the underlying linear model using plt.plot().**\n",
    "\n",
    "**First feed in** `X_test` **as the x-axis and** `X_test*slope + intercept` **as the y-axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Use** `plt.scatter` **to plot** `X_test` **and** `y_test`, **and also to plot** `curve_x` and `curve_y` **which show the curve of the logistic classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_x = np.linspace(-100, 200, 100).reshape(-1, 1)\n",
    "curve_y = [a for a,b in model.predict_proba(curve_x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What is your own probability of survival? Because the model expects a dataframe, you'll need to wrap your age in lists. So if your age is 50, you'll input** `[[50]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Use one-hot encoding to add all the columns to your model. Call model.score() to see the accuracy of your model.**\n",
    "\n",
    "Hint: Use `make_column_transformer` to separate categorical and numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Evaluating Classifiers\n",
    "\n",
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test accuracy of your model:** `pipeline.score(X_test, y_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create confusion matrix:** \n",
    "```python\n",
    "pipeline = ConfusionMatrix(pipeline)\n",
    "pipeline.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot class prediction error:**\n",
    "```\n",
    "pipeline = ClassPredictionError(pipeline)\n",
    "pipeline.score(X_test, y_test)\n",
    "```                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot ROC curve:** \n",
    "```python\n",
    "pipeline = ROCAUC(pipeline)\n",
    "pipeline.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Plot the confusion matrix. What is more common -- false positives or false negatives?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plot the class prediction error. Which class has a higher rate of error?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Create an ROC curve for the model. Is the model closer to an ideal model or random chance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Class Imbalance\n",
    "\n",
    "### Warm Ups\n",
    "\n",
    "*Type the given code into the cell below*\n",
    "\n",
    "---\n",
    "\n",
    "**Plot the class balance**: \n",
    "```python\n",
    "viz = ClassBalance()\n",
    "viz.fit(y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot precision-recall curve:**\n",
    "```\n",
    "pipeline = PrecisionRecallCurve(pipeline)\n",
    "pipeline.score(X_test, y_test)\n",
    "```                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a balanced model:** \n",
    "```python\n",
    "pipeline = make_pipeline(RandomOverSampler(), trans, LogisticRegression())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "---\n",
    "\n",
    "**1. Make a ClassBalance visualization. Which class is overrepresented in this dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plot a precision-recall curve of this imbalanced dataset. How does this graph compare to the ROC curve?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Create a new model that uses RandomOverSampler() as part of the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
